{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7517af25-af10-498b-a4fa-d8d24508c3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a18c9da-ed8a-4d74-bbd3-f4c9aa15931a",
   "metadata": {},
   "source": [
    "Trasformiamo i tre set dandoli in pasto prima allo scaler che renderà ogni feature con media nulla e varianza 1, li diamo in pasto \n",
    "alla PCA e poi li salviamo pronti per essere usati per il train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9fcac88-4935-4b9b-af48-916d42d32bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Definiamo il metodo che apre tutti i batch, li trasforma uno per uno e li salva in una cartella diversa\n",
    "def rescale_pca_data (origin_path,destination_path,scaler,pca):\n",
    "    origin_batch_paths=[origin_path+path for path in os.listdir(origin_path)]\n",
    "    #### Per i destination file prendiamo gli stessi nomi nell'origin_path in modo che si chiamino allo stesso modo\n",
    "    destination_batch_paths=[destination_path+path for path in os.listdir(origin_path)]\n",
    "    for i in range(len(origin_batch_paths)):\n",
    "        with open(origin_batch_paths[i],'rb') as f:\n",
    "            data=pickle.load(f)\n",
    "        pca_data=pca.transform(scaler.transform(data))\n",
    "        with open(destination_batch_paths[i],'wb') as f:\n",
    "            pickle.dump(pca_data,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec88feb3-1ff3-4206-bb44-4260ef7a0976",
   "metadata": {},
   "source": [
    "'/home/private/Hepd/Dataset_4/train/train_norm_data/'\n",
    "'/home/private/Hepd/Dataset_4/train/train_pca_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "513fda1b-cea5-4d66-8a6b-45877b2a454a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### otteniamo la scaler fittato sul train set\n",
    "with open('scaler.pkl','rb') as f:\n",
    "    scaler=pickle.load(f)\n",
    "#### oteniamo la pca \n",
    "with open('pca_transform.pkl','rb') as f:\n",
    "    pca=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e88c4c5-04f9-4c4f-94c0-307fed5e08ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### creiamo i data_file in pca del train\n",
    "rescale_pca_data('/home/private/Hepd/Dataset_4/train/train_norm_data/','/home/private/Hepd/Dataset_4/train/train_pca_data/',scaler,pca)\n",
    "#### creiamo i data_file in pca del test\n",
    "rescale_pca_data('/home/private/Hepd/Dataset_4/test/test_norm_data/','/home/private/Hepd/Dataset_4/test/test_pca_data/',scaler,pca)\n",
    "#### creiamo i data_file in pca del validation\n",
    "rescale_pca_data('/home/private/Hepd/Dataset_4/validation/validation_norm_data/','/home/private/Hepd/Dataset_4/validation/validation_pca_data/',scaler,pca)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HERD",
   "language": "python",
   "name": "hep2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
