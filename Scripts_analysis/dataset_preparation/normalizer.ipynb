{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c23d3c2-4991-4d60-9ed9-c821739ea0fe",
   "metadata": {},
   "source": [
    "troviamo massimi e minimi di lyso e adc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bd93b9bf-010d-4c6e-9cbc-719c7bc63f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c7c044-f33b-470f-9e47-ccd5e9ff7a5a",
   "metadata": {},
   "source": [
    "Cerchiamo i minimi e i massimo sia per il lyso che per ADC\n",
    "Il lyso Ã¨ rappresentato dagli ultimi 9 numeri e ADC dai primi 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "17e1ef23-0664-42bd-af5a-f585ddfe42e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/private/Hepd/Dataset_4/massimi_minimi/massimo_adc_train.pkl','rb') as f:\n",
    "    massimo_adc=pickle.load(f)\n",
    "    massimo_adc_train=massimo_adc\n",
    "with open('/home/private/Hepd/Dataset_4/massimi_minimi/massimo_adc_test.pkl','rb') as f:\n",
    "    massimo_adc_test=pickle.load(f)\n",
    "    if massimo_adc<massimo_adc_test:\n",
    "        massimo_adc=massimo_adc_test\n",
    "with open('/home/private/Hepd/Dataset_4/massimi_minimi/massimo_adc_validation.pkl','rb') as f:\n",
    "    massimo_adc_validation=pickle.load(f)\n",
    "    if massimo_adc<massimo_adc_validation:\n",
    "        massimo_adc=massimo_adc_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6db4c01a-cb69-429c-9399-dfd8689fd9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/private/Hepd/Dataset_4/massimi_minimi/minimo_adc_train.pkl','rb') as f:\n",
    "    minimo_adc=pickle.load(f)\n",
    "    minimo_adc_train = minimo_adc\n",
    "with open('/home/private/Hepd/Dataset_4/massimi_minimi/minimo_adc_test.pkl','rb')as f:\n",
    "    minimo_adc_test=pickle.load(f)\n",
    "    if minimo_adc_test<minimo_adc:\n",
    "        minimo_adc=minimo_adc_test\n",
    "with open('/home/private/Hepd/Dataset_4/massimi_minimi/minimo_adc_validation.pkl','rb') as f:\n",
    "    minimo_adc_validation=pickle.load(f)\n",
    "    if minimo_adc_validation<minimo_adc:\n",
    "        minimo_adc=minimo_adc_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "20235b86-685c-4b9f-ac8a-b937e56bc371",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/private/Hepd/Dataset_4/massimi_minimi/massimo_lyso_train.pkl','rb') as f:\n",
    "    massimo_lyso=pickle.load(f)\n",
    "    massimo_lyso_train = massimo_lyso\n",
    "with open('/home/private/Hepd/Dataset_4/massimi_minimi/massimo_lyso_test.pkl','rb') as f:\n",
    "    massimo_lyso_test=pickle.load(f)\n",
    "    if massimo_lyso_test>massimo_lyso:\n",
    "        massimo_lyso=massimo_lyso_test\n",
    "with open('/home/private/Hepd/Dataset_4/massimi_minimi/massimo_lyso_validation.pkl','rb')as f:\n",
    "    massimo_lyso_validation=pickle.load(f)\n",
    "    if massimo_lyso_validation>massimo_lyso:\n",
    "        massimo_lyso=massimo_lyso_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5f4b5871-5e2d-4ef7-8709-cdd00b2852f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/private/Hepd/Dataset_4/massimi_minimi/minimo_lyso_train.pkl','rb') as f:\n",
    "    minimo_lyso=pickle.load(f)\n",
    "    minimo_lyso_train = minimo_lyso\n",
    "with open('/home/private/Hepd/Dataset_4/massimi_minimi/minimo_lyso_test.pkl','rb') as f:\n",
    "    minimo_lyso_test=pickle.load(f)\n",
    "    if minimo_lyso_test<minimo_lyso:\n",
    "        minimo_lyso=minimo_lyso_test\n",
    "with open('/home/private/Hepd/Dataset_4/massimi_minimi/minimo_lyso_validation.pkl','rb') as f:\n",
    "    minimo_lyso_validation=pickle.load(f)\n",
    "    if minimo_lyso_validation<minimo_lyso:\n",
    "        minimo_lyso=minimo_lyso_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "765d5a3d-e10f-47d8-b94c-1eebd7dc09bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_dir='/home/private/Hepd/Dataset_4/train/train_labels'\n",
    "test_labels_dir='/home/private/Hepd/Dataset_4/test/test_labels'\n",
    "validation_labels_dir='/home/private/Hepd/Dataset_4/validation/validation_labels'\n",
    "\n",
    "num_batches_train=len([f for f in os.listdir(train_labels_dir) if os.path.isfile(os.path.join(train_labels_dir, f))])\n",
    "num_batches_test=len([f for f in os.listdir(test_labels_dir) if os.path.isfile(os.path.join(test_labels_dir, f))])\n",
    "num_batches_validation=len([f for f in os.listdir(validation_labels_dir) if os.path.isfile(os.path.join(validation_labels_dir, f))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5ae90c-2293-4870-b5f2-290aa72d8345",
   "metadata": {},
   "source": [
    "Normalizziamo sui utilizzando i massimi e i minimi del train_set non quelli generali di tutto il dataset\n",
    "- moltiplichiamo il massimo del train per un fattore (> di 1) in modo da essere sicuri che il massimo di normalizzazione possa essere superiore a tutti i valori del dataset (scegliamo di aumetnare il massimo del 10%)\n",
    "- moltiplichiamo il minimo del train per un fattore (< 1) in modo da essere sicuri che il minimo di normalizzazione possa essere inferiore a tutti i valori del dataset (scegliamo di dimunuire il minimo del 10%).\n",
    "\n",
    "FACENDO QUESTA OPERAZIONE DOBBIAMO FARE ATTENZIONE SUL SEGNO DI QUESTI MASSIMI E QUESTI MINIMI, SE SONO NEGATIVI DOBBIAMO INVERTIRE I COEFFICENTI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9c46f02b-d7cc-401c-ba94-3fbd5824c8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "increasing_coefficent = 1.1\n",
    "decreasing_coefficent = 0.9\n",
    "if massimo_adc_train > 0:\n",
    "    massimo_adc_train_increased = massimo_adc_train * increasing_coefficent\n",
    "else:\n",
    "    massimo_adc_train_increased = massimo_adc_train * decreasing_coefficent\n",
    "\n",
    "if massimo_lyso_train > 0:\n",
    "    massimo_lyso_train_increased = massimo_lyso_train * increasing_coefficent\n",
    "else:\n",
    "    massimo_lyso_train_increased = massimo_lyso_train * decreasing_coefficent\n",
    "\n",
    "if minimo_adc_train > 0:\n",
    "    minimo_adc_train_decreased = minimo_adc_train * decreasing_coefficent\n",
    "else:\n",
    "    minimo_adc_train_decreased = minimo_adc_train * increasing_coefficent\n",
    "\n",
    "if minimo_lyso_train > 0:\n",
    "    minimo_lyso_train_decreased = minimo_lyso_train * decreasing_coefficent\n",
    "else:\n",
    "    minimo_lyso_train_decreased = minimo_lyso_train * increasing_coefficent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952f32f8-ac31-482d-aea5-ab783d302595",
   "metadata": {},
   "source": [
    "Normalizziamo i valori i dati in base al massimo increased e al minimo decreased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7440ad48-50f6-4e6f-a550-993c153862c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_batches_train):\n",
    "    with open('/home/private/Hepd/Dataset_4/train/train_data/'+str(i)+'.pkl','rb') as f:\n",
    "        data=pickle.load(f)\n",
    "        if len(data)!=0:\n",
    "            data_norm=np.zeros((len(data),len(data[0])))\n",
    "        else: break\n",
    "        for j in range(len(data)):\n",
    "            norm_adc=((data[j][:31]-minimo_adc_train_decreased)/(massimo_adc_train_increased-minimo_adc_train_decreased))\n",
    "            norm_lyso=((data[j][31:]-minimo_lyso_train_decreased)/(massimo_lyso_train_increased-minimo_lyso_train_decreased))\n",
    "            data_norm[j]=np.concatenate((norm_adc,norm_lyso))\n",
    "    with open('/home/private/Hepd/Dataset_4/train/train_norm_data/'+str(i)+'.pkl','wb') as f:\n",
    "        pickle.dump(data_norm,f)\n",
    "\n",
    "\n",
    "for i in range(num_batches_test):\n",
    "    with open('/home/private/Hepd/Dataset_4/test/test_data/'+str(i)+'.pkl','rb') as f:\n",
    "        data=pickle.load(f)\n",
    "        if len(data)!=0:\n",
    "            data_norm=np.zeros((len(data),len(data[0])))\n",
    "        else: break\n",
    "        for j in range(len(data)):\n",
    "            norm_adc=((data[j][:31]-minimo_adc_train_decreased)/(massimo_adc_train_increased-minimo_adc_train_decreased))\n",
    "            norm_lyso=((data[j][31:]-minimo_lyso_train_decreased)/(massimo_lyso_train_increased-minimo_lyso_train_decreased))\n",
    "            data_norm[j]=np.concatenate((norm_adc,norm_lyso))\n",
    "    with open('/home/private/Hepd/Dataset_4/test/test_norm_data/'+str(i)+'.pkl','wb') as f:\n",
    "        pickle.dump(data_norm,f)\n",
    "\n",
    "\n",
    "for i in range(num_batches_validation):\n",
    "    with open('/home/private/Hepd/Dataset_4/validation/validation_data/'+str(i)+'.pkl','rb') as f:\n",
    "        data=pickle.load(f)\n",
    "        if len(data)!=0:\n",
    "            data_norm=np.zeros((len(data),len(data[0])))\n",
    "        else: break\n",
    "        for j in range(len(data)):\n",
    "            norm_adc=((data[j][:31]-minimo_adc_train_decreased)/(massimo_adc_train_increased-minimo_adc_train_decreased))\n",
    "            norm_lyso=((data[j][31:]-minimo_lyso_train_decreased)/(massimo_lyso_train_increased-minimo_lyso_train_decreased))\n",
    "            data_norm[j]=np.concatenate((norm_adc,norm_lyso))\n",
    "    with open('/home/private/Hepd/Dataset_4/validation/validation_norm_data/'+str(i)+'.pkl','wb') as f:\n",
    "        pickle.dump(data_norm,f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
