{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3196501e-69df-42ef-b123-2e8c89df3267",
   "metadata": {},
   "source": [
    "Creiamo delle reti fully connceted per la classificazione degli elettroni vs protoni a bassa energia per Hepd. Vogliamo provare ad avere un campione di elttroni pulito da questi eventi protonici che mimano nel detector degli eventi elettronici rilasciando energia nei primi layer.\n",
    "Abbiamo già tentato con BDT,CNN e fcnn ora proviamo con reti fully connected con geometrie particolari: proviamo con imbuti o piramidi (partire stretti e poi allergarsi o viceversa). Non abbiamo grandi speranze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e601f4f-b4dc-489b-84b0-259cd8b52b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "\n",
    "from keras import Model\n",
    "from keras.layers import Input, Dense,Dropout\n",
    "\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fd20a2-af7f-4a50-a472-fc98780a0d5e",
   "metadata": {},
   "source": [
    "creaimo un segmento di codice che aggiunga layer densi con numero di neuroni che si incrementa o che diminuisce in maniera lineare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2cafe36-896a-4a51-8997-4b0d0ac59def",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''creiamo la funzione che riceva in input:\n",
    "-num_layers il numero di layer densi da aggiungere\n",
    "-neurons_init il numero iniziale di neuroni nel layer\n",
    "-neurons_fin il numero finale di neuroni\n",
    "-pace il numero di layer da aggiungere prima di modificare il numero di neuroni\n",
    "'''\n",
    "class dense_block_lin:\n",
    "    def __init__(self):\n",
    "        self.delta=0\n",
    "    def block_creation(self,x,num_layers=5,neurons_init=32,neurons_fin=512,pace=1):\n",
    "        #curr: int numero di neuroni corrente\n",
    "        curr=neurons_init\n",
    "        #delta: int numero di neuroni da aggiungere ogni pace layers\n",
    "        if num_layers!=1:\n",
    "            self.delta=int(((neurons_fin-neurons_init)/(num_layers-1)))*pace\n",
    "        else:\n",
    "            delta=0\n",
    "        for i in range(num_layers-1):\n",
    "            if i!=0 and i%pace==0:\n",
    "                curr+=self.delta\n",
    "            x=Dense(curr,activation='relu')(x)\n",
    "        x=Dense(neurons_fin,activation='relu')(x)\n",
    "        return x    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "2849771a-d131-4abd-8b5e-0f71a34d9306",
   "metadata": {},
   "source": [
    "Creiamo il modello definiendo la depth e il numero di neuroni iniziali e finali,\n",
    "vogliamo testare vari modelli con profondità diverse e larghezze diverse:\n",
    "-maggiore depth implica un network più profondi\n",
    "-maggiore numero di neuroni implica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecdaf39d-6ecf-4ab4-b335-c3c1a6a0285d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "deiniamo una funzione in grado di approssimare il numero totale di paramteri alle migliaia:\n",
    "\n",
    "1400 -> 1000\n",
    "1500 -> 2000\n",
    "\n",
    "12400 -> 12000\n",
    "12500 -> 13000\n",
    "\n",
    "100400 -> 100000 \n",
    "100500 -> 101000\n",
    "'''\n",
    "\n",
    "def approssima_alle_migliaia(numero):\n",
    "    return int(np.ceil((numero/1000)-0.499)*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5939c8-c5f9-4cea-88dd-cddcccbe89de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Creaimo le reti per i dati normalizzati, quindi la dimensione in input è di 40\n",
    "depths=[2,3,5,7,8,9,11,12,14,16,18]\n",
    "neur_low=16\n",
    "high_neurons=[32,54,64,94,128,170,210,256,320,410,512]\n",
    "i=0\n",
    "#### NOTA BENE PER LE ARCHITETTURE FUNNEL E BOTTLE NON CONSIDERIAMO high_neurons=32 CON DEPTH 20 PERCHè IL MODELLO RISULTANTE \n",
    "#### AVREBBE IN REALTà UN'ARCHITETTURA CONSTANT\n",
    "for depth in depths:\n",
    "    for neur_high in high_neurons:\n",
    "        #de-commenta la riga successiva per creare i modelli bottle \n",
    "        #neurons=[neur_low,neur_high]\n",
    "        #de-commenta la riga successiva per creare i \n",
    "        #neurons=[neur_high,neur_low]\n",
    "        \n",
    "        #### DOBBIAMO EVITARE DI CREARE IL MODELLO CON ULTIMO LAYER DA 32 E DEPTH DA 20 SE L'ARCHITETTURA DA CREARE NON è CONSTANT \n",
    "        #### COMMENTA LE PROSSIMA DUE RIGHE E DE-COMMENTA LA RIGA SEGUENTE PER I MODELLI CONSTANT\n",
    "        \n",
    "        #if neur_high==32 and depth==18: continue\n",
    "        #else:\n",
    "            neurons=[neur_high,neur_high]\n",
    "            input_dim=(40,)\n",
    "            input_layer=Input(shape=input_dim)\n",
    "            dense_block=dense_block_lin()\n",
    "            central_block=dense_block.block_creation(input_layer,num_layers=depth,neurons_init=neurons[0],neurons_fin=neurons[1])\n",
    "            output=Dense(1,activation='sigmoid')(central_block)\n",
    "            model=Model(input_layer,output)\n",
    "            print('numero di parametri: ',model.count_params())\n",
    "            print('numero di layers: ',len(model.layers))\n",
    "            print('numero di neuroni del layer più largo: ',neur_high)\n",
    "            \n",
    "            warnings.filterwarnings('ignore')\n",
    "            \n",
    "            ### DEFINIAMO IL TIPO DI ARCHITETTURA IN BASE ALLA VARIAZIONE DELLA LARGHEZZA DEI LAYER NEL NETWORK:\n",
    "            # bottle : larghezza che aumenta\n",
    "            # funnel : larghezza che diminuisce (imbuto)\n",
    "            # constant : larghezza costante\n",
    "            # general : larghezza senza andamento fisso\n",
    "            architecture='general'\n",
    "            if dense_block.delta>0:\n",
    "                architecture='bottle'\n",
    "            elif dense_block.delta<0:\n",
    "                architecture='funnel'\n",
    "            elif dense_block.delta==0:\n",
    "                architecture='constant'\n",
    "            \n",
    "            print(architecture)\n",
    "            print(i)\n",
    "            i+=1\n",
    "            \n",
    "            tot_par=approssima_alle_migliaia(model.count_params())\n",
    "            num_layers=len(model.layers)\n",
    "            N=len(str(tot_par))-3\n",
    "            str_par=str(tot_par)[:N]+'k'\n",
    "            str_num_layers='depth_'+str(num_layers)\n",
    "            modello_json = model.to_json()\n",
    "            \n",
    "            '''\n",
    "            Salviamo l modello. Nella cartella fcNN troveremo una cartella per modello con il nome simile a:\n",
    "            \n",
    "            depth_11_201k :   in questa cartella troveremo un modello di profondità 11 e 201mila parametri, in particolare:\n",
    "            \n",
    "            - depth_11_201k_plot.png    : plot del modello\n",
    "            - depth_11_201k_summary.txt : summary del modello\n",
    "            - depth_11_201k.json        : modello pre-trainato\n",
    "            '''\n",
    "            \n",
    "            if not os.path.exists('/home/private/Hepd/Dataset_4/fcNN/'+architecture+'/'+architecture+'_'+str_num_layers+'_'+str(neur_high)):\n",
    "                os.makedirs('/home/private/Hepd/Dataset_4/fcNN/'+architecture+'/'+architecture+'_'+str_num_layers+'_'+str(neur_high))\n",
    "                    \n",
    "            with open('/home/private/Hepd/Dataset_4/fcNN/'+architecture+'/'+architecture+'_'+str_num_layers+'_'+str(neur_high)+'/'+\n",
    "                      architecture+'_'+str_num_layers+'_'+str(neur_high)+'.json', 'w') as f:\n",
    "                f.write(modello_json)\n",
    "            #model.summary()\n",
    "            with open('/home/private/Hepd/Dataset_4/fcNN/'+architecture+'/'+architecture+'_'+str_num_layers+'_'+str(neur_high)+'/'+\n",
    "                      architecture+'_'+str_num_layers+'_'+str(neur_high)+'_summary.txt', 'w') as f:\n",
    "                model.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
    "            plot_model(model, to_file='/home/private/Hepd/Dataset_4/fcNN/'+architecture+'/'+architecture+'_'+str_num_layers+'_'+str(neur_high)+'/'+\n",
    "            architecture+'_'+str_num_layers+'_'+str(neur_high)+'_plot.png',show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37972a06-0c3a-4b31-9baa-9f99641a7cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numero di parametri:  1249\n",
      "numero di layers:  4\n",
      "numero di neuroni del layer più largo:  32\n",
      "constant\n",
      "0\n",
      "numero di parametri:  3295\n",
      "numero di layers:  4\n",
      "numero di neuroni del layer più largo:  54\n",
      "constant\n",
      "1\n",
      "numero di parametri:  4545\n",
      "numero di layers:  4\n",
      "numero di neuroni del layer più largo:  64\n",
      "constant\n",
      "2\n",
      "numero di parametri:  9495\n",
      "numero di layers:  4\n",
      "numero di neuroni del layer più largo:  94\n",
      "constant\n",
      "3\n",
      "numero di parametri:  17281\n",
      "numero di layers:  4\n",
      "numero di neuroni del layer più largo:  128\n",
      "constant\n",
      "4\n",
      "numero di parametri:  30091\n",
      "numero di layers:  4\n",
      "numero di neuroni del layer più largo:  170\n",
      "constant\n",
      "5\n",
      "numero di parametri:  45571\n",
      "numero di layers:  4\n",
      "numero di neuroni del layer più largo:  210\n",
      "constant\n",
      "6\n",
      "numero di parametri:  67329\n",
      "numero di layers:  4\n",
      "numero di neuroni del layer più largo:  256\n",
      "constant\n",
      "7\n",
      "numero di parametri:  104641\n",
      "numero di layers:  4\n",
      "numero di neuroni del layer più largo:  320\n",
      "constant\n",
      "8\n",
      "numero di parametri:  170971\n",
      "numero di layers:  4\n",
      "numero di neuroni del layer più largo:  410\n",
      "constant\n",
      "9\n",
      "numero di parametri:  265729\n",
      "numero di layers:  4\n",
      "numero di neuroni del layer più largo:  512\n",
      "constant\n",
      "10\n",
      "numero di parametri:  2305\n",
      "numero di layers:  5\n",
      "numero di neuroni del layer più largo:  32\n",
      "constant\n",
      "11\n",
      "numero di parametri:  6265\n",
      "numero di layers:  5\n",
      "numero di neuroni del layer più largo:  54\n",
      "constant\n",
      "12\n",
      "numero di parametri:  8705\n",
      "numero di layers:  5\n",
      "numero di neuroni del layer più largo:  64\n",
      "constant\n",
      "13\n",
      "numero di parametri:  18425\n",
      "numero di layers:  5\n",
      "numero di neuroni del layer più largo:  94\n",
      "constant\n",
      "14\n",
      "numero di parametri:  33793\n",
      "numero di layers:  5\n",
      "numero di neuroni del layer più largo:  128\n",
      "constant\n",
      "15\n",
      "numero di parametri:  59161\n",
      "numero di layers:  5\n",
      "numero di neuroni del layer più largo:  170\n",
      "constant\n",
      "16\n",
      "numero di parametri:  89881\n",
      "numero di layers:  5\n",
      "numero di neuroni del layer più largo:  210\n",
      "constant\n",
      "17\n",
      "numero di parametri:  133121\n",
      "numero di layers:  5\n",
      "numero di neuroni del layer più largo:  256\n",
      "constant\n",
      "18\n",
      "numero di parametri:  207361\n",
      "numero di layers:  5\n",
      "numero di neuroni del layer più largo:  320\n",
      "constant\n",
      "19\n",
      "numero di parametri:  339481\n",
      "numero di layers:  5\n",
      "numero di neuroni del layer più largo:  410\n",
      "constant\n",
      "20\n",
      "numero di parametri:  528385\n",
      "numero di layers:  5\n",
      "numero di neuroni del layer più largo:  512\n",
      "constant\n",
      "21\n",
      "numero di parametri:  4417\n",
      "numero di layers:  7\n",
      "numero di neuroni del layer più largo:  32\n",
      "constant\n",
      "22\n",
      "numero di parametri:  12205\n",
      "numero di layers:  7\n",
      "numero di neuroni del layer più largo:  54\n",
      "constant\n",
      "23\n",
      "numero di parametri:  17025\n",
      "numero di layers:  7\n",
      "numero di neuroni del layer più largo:  64\n",
      "constant\n",
      "24\n",
      "numero di parametri:  36285\n",
      "numero di layers:  7\n",
      "numero di neuroni del layer più largo:  94\n",
      "constant\n",
      "25\n",
      "numero di parametri:  66817\n",
      "numero di layers:  7\n",
      "numero di neuroni del layer più largo:  128\n",
      "constant\n",
      "26\n",
      "numero di parametri:  117301\n",
      "numero di layers:  7\n",
      "numero di neuroni del layer più largo:  170\n",
      "constant\n",
      "27\n",
      "numero di parametri:  178501\n",
      "numero di layers:  7\n",
      "numero di neuroni del layer più largo:  210\n",
      "constant\n",
      "28\n",
      "numero di parametri:  264705\n",
      "numero di layers:  7\n",
      "numero di neuroni del layer più largo:  256\n",
      "constant\n",
      "29\n",
      "numero di parametri:  412801\n",
      "numero di layers:  7\n",
      "numero di neuroni del layer più largo:  320\n",
      "constant\n",
      "30\n",
      "numero di parametri:  676501\n",
      "numero di layers:  7\n",
      "numero di neuroni del layer più largo:  410\n",
      "constant\n",
      "31\n",
      "numero di parametri:  1053697\n",
      "numero di layers:  7\n",
      "numero di neuroni del layer più largo:  512\n",
      "constant\n",
      "32\n",
      "numero di parametri:  6529\n",
      "numero di layers:  9\n",
      "numero di neuroni del layer più largo:  32\n",
      "constant\n",
      "33\n",
      "numero di parametri:  18145\n",
      "numero di layers:  9\n",
      "numero di neuroni del layer più largo:  54\n",
      "constant\n",
      "34\n",
      "numero di parametri:  25345\n",
      "numero di layers:  9\n",
      "numero di neuroni del layer più largo:  64\n",
      "constant\n",
      "35\n",
      "numero di parametri:  54145\n",
      "numero di layers:  9\n",
      "numero di neuroni del layer più largo:  94\n",
      "constant\n",
      "36\n",
      "numero di parametri:  99841\n",
      "numero di layers:  9\n",
      "numero di neuroni del layer più largo:  128\n",
      "constant\n",
      "37\n",
      "numero di parametri:  175441\n",
      "numero di layers:  9\n",
      "numero di neuroni del layer più largo:  170\n",
      "constant\n",
      "38\n",
      "numero di parametri:  267121\n",
      "numero di layers:  9\n",
      "numero di neuroni del layer più largo:  210\n",
      "constant\n",
      "39\n",
      "numero di parametri:  396289\n",
      "numero di layers:  9\n",
      "numero di neuroni del layer più largo:  256\n",
      "constant\n",
      "40\n",
      "numero di parametri:  618241\n",
      "numero di layers:  9\n",
      "numero di neuroni del layer più largo:  320\n",
      "constant\n",
      "41\n",
      "numero di parametri:  1013521\n",
      "numero di layers:  9\n",
      "numero di neuroni del layer più largo:  410\n",
      "constant\n",
      "42\n",
      "numero di parametri:  1579009\n",
      "numero di layers:  9\n",
      "numero di neuroni del layer più largo:  512\n",
      "constant\n",
      "43\n",
      "numero di parametri:  7585\n",
      "numero di layers:  10\n",
      "numero di neuroni del layer più largo:  32\n",
      "constant\n",
      "44\n",
      "numero di parametri:  21115\n",
      "numero di layers:  10\n",
      "numero di neuroni del layer più largo:  54\n",
      "constant\n",
      "45\n",
      "numero di parametri:  29505\n",
      "numero di layers:  10\n",
      "numero di neuroni del layer più largo:  64\n",
      "constant\n",
      "46\n",
      "numero di parametri:  63075\n",
      "numero di layers:  10\n",
      "numero di neuroni del layer più largo:  94\n",
      "constant\n",
      "47\n",
      "numero di parametri:  116353\n",
      "numero di layers:  10\n",
      "numero di neuroni del layer più largo:  128\n",
      "constant\n",
      "48\n",
      "numero di parametri:  204511\n",
      "numero di layers:  10\n",
      "numero di neuroni del layer più largo:  170\n",
      "constant\n",
      "49\n",
      "numero di parametri:  311431\n",
      "numero di layers:  10\n",
      "numero di neuroni del layer più largo:  210\n",
      "constant\n",
      "50\n",
      "numero di parametri:  462081\n",
      "numero di layers:  10\n",
      "numero di neuroni del layer più largo:  256\n",
      "constant\n",
      "51\n",
      "numero di parametri:  720961\n",
      "numero di layers:  10\n",
      "numero di neuroni del layer più largo:  320\n",
      "constant\n",
      "52\n",
      "numero di parametri:  1182031\n",
      "numero di layers:  10\n",
      "numero di neuroni del layer più largo:  410\n",
      "constant\n",
      "53\n",
      "numero di parametri:  1841665\n",
      "numero di layers:  10\n",
      "numero di neuroni del layer più largo:  512\n",
      "constant\n",
      "54\n",
      "numero di parametri:  8641\n",
      "numero di layers:  11\n",
      "numero di neuroni del layer più largo:  32\n",
      "constant\n",
      "55\n",
      "numero di parametri:  24085\n",
      "numero di layers:  11\n",
      "numero di neuroni del layer più largo:  54\n",
      "constant\n",
      "56\n",
      "numero di parametri:  33665\n",
      "numero di layers:  11\n",
      "numero di neuroni del layer più largo:  64\n",
      "constant\n",
      "57\n",
      "numero di parametri:  72005\n",
      "numero di layers:  11\n",
      "numero di neuroni del layer più largo:  94\n",
      "constant\n",
      "58\n",
      "numero di parametri:  132865\n",
      "numero di layers:  11\n",
      "numero di neuroni del layer più largo:  128\n",
      "constant\n",
      "59\n",
      "numero di parametri:  233581\n",
      "numero di layers:  11\n",
      "numero di neuroni del layer più largo:  170\n",
      "constant\n",
      "60\n",
      "numero di parametri:  355741\n",
      "numero di layers:  11\n",
      "numero di neuroni del layer più largo:  210\n",
      "constant\n",
      "61\n",
      "numero di parametri:  527873\n",
      "numero di layers:  11\n",
      "numero di neuroni del layer più largo:  256\n",
      "constant\n",
      "62\n",
      "numero di parametri:  823681\n",
      "numero di layers:  11\n",
      "numero di neuroni del layer più largo:  320\n",
      "constant\n",
      "63\n",
      "numero di parametri:  1350541\n",
      "numero di layers:  11\n",
      "numero di neuroni del layer più largo:  410\n",
      "constant\n",
      "64\n",
      "numero di parametri:  2104321\n",
      "numero di layers:  11\n",
      "numero di neuroni del layer più largo:  512\n",
      "constant\n",
      "65\n",
      "numero di parametri:  10753\n",
      "numero di layers:  13\n",
      "numero di neuroni del layer più largo:  32\n",
      "constant\n",
      "66\n",
      "numero di parametri:  30025\n",
      "numero di layers:  13\n",
      "numero di neuroni del layer più largo:  54\n",
      "constant\n",
      "67\n",
      "numero di parametri:  41985\n",
      "numero di layers:  13\n",
      "numero di neuroni del layer più largo:  64\n",
      "constant\n",
      "68\n",
      "numero di parametri:  89865\n",
      "numero di layers:  13\n",
      "numero di neuroni del layer più largo:  94\n",
      "constant\n",
      "69\n",
      "numero di parametri:  165889\n",
      "numero di layers:  13\n",
      "numero di neuroni del layer più largo:  128\n",
      "constant\n",
      "70\n",
      "numero di parametri:  291721\n",
      "numero di layers:  13\n",
      "numero di neuroni del layer più largo:  170\n",
      "constant\n",
      "71\n",
      "numero di parametri:  444361\n",
      "numero di layers:  13\n",
      "numero di neuroni del layer più largo:  210\n",
      "constant\n",
      "72\n",
      "numero di parametri:  659457\n",
      "numero di layers:  13\n",
      "numero di neuroni del layer più largo:  256\n",
      "constant\n",
      "73\n",
      "numero di parametri:  1029121\n",
      "numero di layers:  13\n",
      "numero di neuroni del layer più largo:  320\n",
      "constant\n",
      "74\n",
      "numero di parametri:  1687561\n",
      "numero di layers:  13\n",
      "numero di neuroni del layer più largo:  410\n",
      "constant\n",
      "75\n",
      "numero di parametri:  2629633\n",
      "numero di layers:  13\n",
      "numero di neuroni del layer più largo:  512\n",
      "constant\n",
      "76\n",
      "numero di parametri:  11809\n",
      "numero di layers:  14\n",
      "numero di neuroni del layer più largo:  32\n",
      "constant\n",
      "77\n",
      "numero di parametri:  32995\n",
      "numero di layers:  14\n",
      "numero di neuroni del layer più largo:  54\n",
      "constant\n",
      "78\n",
      "numero di parametri:  46145\n",
      "numero di layers:  14\n",
      "numero di neuroni del layer più largo:  64\n",
      "constant\n",
      "79\n",
      "numero di parametri:  98795\n",
      "numero di layers:  14\n",
      "numero di neuroni del layer più largo:  94\n",
      "constant\n",
      "80\n",
      "numero di parametri:  182401\n",
      "numero di layers:  14\n",
      "numero di neuroni del layer più largo:  128\n",
      "constant\n",
      "81\n",
      "numero di parametri:  320791\n",
      "numero di layers:  14\n",
      "numero di neuroni del layer più largo:  170\n",
      "constant\n",
      "82\n",
      "numero di parametri:  488671\n",
      "numero di layers:  14\n",
      "numero di neuroni del layer più largo:  210\n",
      "constant\n",
      "83\n",
      "numero di parametri:  725249\n",
      "numero di layers:  14\n",
      "numero di neuroni del layer più largo:  256\n",
      "constant\n",
      "84\n",
      "numero di parametri:  1131841\n",
      "numero di layers:  14\n",
      "numero di neuroni del layer più largo:  320\n",
      "constant\n",
      "85\n",
      "numero di parametri:  1856071\n",
      "numero di layers:  14\n",
      "numero di neuroni del layer più largo:  410\n",
      "constant\n",
      "86\n",
      "numero di parametri:  2892289\n",
      "numero di layers:  14\n",
      "numero di neuroni del layer più largo:  512\n",
      "constant\n",
      "87\n",
      "numero di parametri:  13921\n",
      "numero di layers:  16\n",
      "numero di neuroni del layer più largo:  32\n",
      "constant\n",
      "88\n",
      "numero di parametri:  38935\n",
      "numero di layers:  16\n",
      "numero di neuroni del layer più largo:  54\n",
      "constant\n",
      "89\n",
      "numero di parametri:  54465\n",
      "numero di layers:  16\n",
      "numero di neuroni del layer più largo:  64\n",
      "constant\n",
      "90\n",
      "numero di parametri:  116655\n",
      "numero di layers:  16\n",
      "numero di neuroni del layer più largo:  94\n",
      "constant\n",
      "91\n",
      "numero di parametri:  215425\n",
      "numero di layers:  16\n",
      "numero di neuroni del layer più largo:  128\n",
      "constant\n",
      "92\n",
      "numero di parametri:  378931\n",
      "numero di layers:  16\n",
      "numero di neuroni del layer più largo:  170\n",
      "constant\n",
      "93\n",
      "numero di parametri:  577291\n",
      "numero di layers:  16\n",
      "numero di neuroni del layer più largo:  210\n",
      "constant\n",
      "94\n",
      "numero di parametri:  856833\n",
      "numero di layers:  16\n",
      "numero di neuroni del layer più largo:  256\n",
      "constant\n",
      "95\n",
      "numero di parametri:  1337281\n",
      "numero di layers:  16\n",
      "numero di neuroni del layer più largo:  320\n",
      "constant\n",
      "96\n",
      "numero di parametri:  2193091\n",
      "numero di layers:  16\n",
      "numero di neuroni del layer più largo:  410\n",
      "constant\n",
      "97\n",
      "numero di parametri:  3417601\n",
      "numero di layers:  16\n",
      "numero di neuroni del layer più largo:  512\n",
      "constant\n",
      "98\n",
      "numero di parametri:  16033\n",
      "numero di layers:  18\n",
      "numero di neuroni del layer più largo:  32\n",
      "constant\n",
      "99\n",
      "numero di parametri:  44875\n",
      "numero di layers:  18\n",
      "numero di neuroni del layer più largo:  54\n",
      "constant\n",
      "100\n",
      "numero di parametri:  62785\n",
      "numero di layers:  18\n",
      "numero di neuroni del layer più largo:  64\n",
      "constant\n",
      "101\n",
      "numero di parametri:  134515\n",
      "numero di layers:  18\n",
      "numero di neuroni del layer più largo:  94\n",
      "constant\n",
      "102\n",
      "numero di parametri:  248449\n",
      "numero di layers:  18\n",
      "numero di neuroni del layer più largo:  128\n",
      "constant\n",
      "103\n",
      "numero di parametri:  437071\n",
      "numero di layers:  18\n",
      "numero di neuroni del layer più largo:  170\n",
      "constant\n",
      "104\n",
      "numero di parametri:  665911\n",
      "numero di layers:  18\n",
      "numero di neuroni del layer più largo:  210\n",
      "constant\n",
      "105\n",
      "numero di parametri:  988417\n",
      "numero di layers:  18\n",
      "numero di neuroni del layer più largo:  256\n",
      "constant\n",
      "106\n",
      "numero di parametri:  1542721\n",
      "numero di layers:  18\n",
      "numero di neuroni del layer più largo:  320\n",
      "constant\n",
      "107\n",
      "numero di parametri:  2530111\n",
      "numero di layers:  18\n",
      "numero di neuroni del layer più largo:  410\n",
      "constant\n",
      "108\n",
      "numero di parametri:  3942913\n",
      "numero di layers:  18\n",
      "numero di neuroni del layer più largo:  512\n",
      "constant\n",
      "109\n",
      "numero di parametri:  18145\n",
      "numero di layers:  20\n",
      "numero di neuroni del layer più largo:  32\n",
      "constant\n",
      "110\n",
      "numero di parametri:  50815\n",
      "numero di layers:  20\n",
      "numero di neuroni del layer più largo:  54\n",
      "constant\n",
      "111\n",
      "numero di parametri:  71105\n",
      "numero di layers:  20\n",
      "numero di neuroni del layer più largo:  64\n",
      "constant\n",
      "112\n",
      "numero di parametri:  152375\n",
      "numero di layers:  20\n",
      "numero di neuroni del layer più largo:  94\n",
      "constant\n",
      "113\n",
      "numero di parametri:  281473\n",
      "numero di layers:  20\n",
      "numero di neuroni del layer più largo:  128\n",
      "constant\n",
      "114\n",
      "numero di parametri:  495211\n",
      "numero di layers:  20\n",
      "numero di neuroni del layer più largo:  170\n",
      "constant\n",
      "115\n",
      "numero di parametri:  754531\n",
      "numero di layers:  20\n",
      "numero di neuroni del layer più largo:  210\n",
      "constant\n",
      "116\n",
      "numero di parametri:  1120001\n",
      "numero di layers:  20\n",
      "numero di neuroni del layer più largo:  256\n",
      "constant\n",
      "117\n",
      "numero di parametri:  1748161\n",
      "numero di layers:  20\n",
      "numero di neuroni del layer più largo:  320\n",
      "constant\n",
      "118\n",
      "numero di parametri:  2867131\n",
      "numero di layers:  20\n",
      "numero di neuroni del layer più largo:  410\n",
      "constant\n",
      "119\n",
      "numero di parametri:  4468225\n",
      "numero di layers:  20\n",
      "numero di neuroni del layer più largo:  512\n",
      "constant\n",
      "120\n"
     ]
    }
   ],
   "source": [
    "#### Creaimo le reti per i dati PCA, quindi la dimensione in input è minore di 40\n",
    "#### scegliamo il numero di dimensioni della PCA da sottomettere\n",
    "input_dimension= 4\n",
    "depths=[2,3,5,7,8,9,11,12,14,16,18]\n",
    "neur_low=16\n",
    "high_neurons=[32,54,64,94,128,170,210,256,320,410,512]\n",
    "i=0\n",
    "#### NOTA BENE PER LE ARCHITETTURE FUNNEL E BOTTLE NON CONSIDERIAMO high_neurons=32 CON DEPTH 20 PERCHè IL MODELLO RISULTANTE \n",
    "#### AVREBBE IN REALTà UN'ARCHITETTURA CONSTANT\n",
    "for depth in depths:\n",
    "    for neur_high in high_neurons:\n",
    "        #de-commenta la riga successiva per creare i modelli bottle \n",
    "        #neurons=[neur_low,neur_high]\n",
    "        #de-commenta la riga successiva per creare i \n",
    "        #neurons=[neur_high,neur_low]\n",
    "        \n",
    "        #### DOBBIAMO EVITARE DI CREARE IL MODELLO CON ULTIMO LAYER DA 32 E DEPTH DA 20 SE L'ARCHITETTURA DA CREARE NON è CONSTANT \n",
    "        #### COMMENTA LE PROSSIME DUE RIGHE E DE-COMMENTA LA RIGA SEGUENTE PER I MODELLI CONSTANT\n",
    "        \n",
    "        #if neur_high==32 and depth==18: continue\n",
    "        #else:\n",
    "            neurons=[neur_high,neur_high]\n",
    "            input_dim=(input_dimension,)\n",
    "            input_layer=Input(shape=input_dim)\n",
    "            dense_block=dense_block_lin()\n",
    "            central_block=dense_block.block_creation(input_layer,num_layers=depth,neurons_init=neurons[0],neurons_fin=neurons[1])\n",
    "            output=Dense(1,activation='sigmoid')(central_block)\n",
    "            model=Model(input_layer,output)\n",
    "            print('numero di parametri: ',model.count_params())\n",
    "            print('numero di layers: ',len(model.layers))\n",
    "            print('numero di neuroni del layer più largo: ',neur_high)\n",
    "            \n",
    "            warnings.filterwarnings('ignore')\n",
    "            \n",
    "            ### DEFINIAMO IL TIPO DI ARCHITETTURA IN BASE ALLA VARIAZIONE DELLA LARGHEZZA DEI LAYER NEL NETWORK:\n",
    "            # bottle : larghezza che aumenta\n",
    "            # funnel : larghezza che diminuisce (imbuto)\n",
    "            # constant : larghezza costante\n",
    "            # general : larghezza senza andamento fisso\n",
    "            architecture='general'\n",
    "            if dense_block.delta>0:\n",
    "                architecture='bottle'\n",
    "            elif dense_block.delta<0:\n",
    "                architecture='funnel'\n",
    "            elif dense_block.delta==0:\n",
    "                architecture='constant'\n",
    "            \n",
    "            print(architecture)\n",
    "            print(i)\n",
    "            i+=1\n",
    "            \n",
    "            tot_par=approssima_alle_migliaia(model.count_params())\n",
    "            num_layers=len(model.layers)\n",
    "            N=len(str(tot_par))-3\n",
    "            str_par=str(tot_par)[:N]+'k'\n",
    "            str_num_layers='depth_'+str(num_layers)\n",
    "            modello_json = model.to_json()\n",
    "            \n",
    "            '''\n",
    "            Salviamo l modello. Nella cartella fcNN troveremo una cartella per modello con il nome simile a:\n",
    "            \n",
    "            depth_11_201k :   in questa cartella troveremo un modello di profondità 11 e 201mila parametri, in particolare:\n",
    "            \n",
    "            - depth_11_201k_plot.png    : plot del modello\n",
    "            - depth_11_201k_summary.txt : summary del modello\n",
    "            - depth_11_201k.json        : modello pre-trainato\n",
    "            '''\n",
    "            \n",
    "            if not os.path.exists('/home/private/Hepd/Dataset_4/fcNN/PCA/'+architecture+'/'+architecture+'_PCA_'+str_num_layers+'_'+str(neur_high)):\n",
    "                os.makedirs('/home/private/Hepd/Dataset_4/fcNN/PCA/'+architecture+'/'+architecture+'_PCA_'+str_num_layers+'_'+str(neur_high))\n",
    "                    \n",
    "            with open('/home/private/Hepd/Dataset_4/fcNN/PCA/'+architecture+'/'+architecture+'_PCA_'+str_num_layers+'_'+str(neur_high)+'/'+\n",
    "                      architecture+'_PCA_'+str_num_layers+'_'+str(neur_high)+'.json', 'w') as f:\n",
    "                f.write(modello_json)\n",
    "            #model.summary()\n",
    "            with open('/home/private/Hepd/Dataset_4/fcNN/PCA/'+architecture+'/'+architecture+'_PCA_'+str_num_layers+'_'+str(neur_high)+'/'+\n",
    "                      architecture+'_PCA_'+str_num_layers+'_'+str(neur_high)+'_summary.txt', 'w') as f:\n",
    "                model.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
    "            plot_model(model, to_file='/home/private/Hepd/Dataset_4/fcNN/PCA/'+architecture+'/'+architecture+'_PCA_'+str_num_layers+'_'+str(neur_high)+'/'+\n",
    "            architecture+'_PCA_'+str_num_layers+'_'+str(neur_high)+'_plot.png',show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "edc9dc31-e339-4531-be88-e95b8bed9adc",
   "metadata": {},
   "source": [
    "salviamo il nostro modello in base alla profondità e in base al numero di parametri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52446e5-1a1e-4f50-9322-e1d58a41bf73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HERD",
   "language": "python",
   "name": "hep2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
